{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "23c6b14b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.documents import Document\n",
    "from langchain.document_loaders import TextLoader\n",
    "from langchain_community.document_loaders import TextLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "719d5bc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Document(metadata={'source': './knowledge_base/dff.txt'}, page_content=\"[Keyword]: Dff\\n\\n[Design Category]: Sequential Logic\\n\\n[Design Function Description]:\\nThis design is a simple D flip-flop. It captures the value of the input signal 'd' on the rising edge of the clock signal 'clk' and outputs it as 'q'. The output 'q' retains its value until the next rising edge of 'clk'.\\n\\n[Input Signal Description]:\\nclk: Clock signal used to synchronize the data capture. The flip-flop captures the input 'd' on the rising edge of this clock.\\nd: Data input signal that is captured by the flip-flop on the rising edge of the clock.\\n\\n[Output Signal Description]:\\nq: The output signal that holds the value of the input 'd' after the rising edge of the clock. It retains this value until the next rising edge of the clock.\\n\\n[Design Detail]: \\nmodule topmodule (\\n    input clk,    // Clocks are used in sequential circuits\\n    input d,\\n    output reg q );//\\n\\n    always @(posedge clk) begin\\n        q <= d;\\n    end\\n\\nendmodule\\n\\n\\n\\n\")]\n"
     ]
    }
   ],
   "source": [
    "loader=TextLoader(\"./knowledge_base/dff.txt\",encoding=\"utf-8\")\n",
    "document=loader.load()\n",
    "print(document)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9bfa57a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'knowledge_base\\\\dff.txt'}, page_content=\"[Keyword]: Dff\\n\\n[Design Category]: Sequential Logic\\n\\n[Design Function Description]:\\nThis design is a simple D flip-flop. It captures the value of the input signal 'd' on the rising edge of the clock signal 'clk' and outputs it as 'q'. The output 'q' retains its value until the next rising edge of 'clk'.\\n\\n[Input Signal Description]:\\nclk: Clock signal used to synchronize the data capture. The flip-flop captures the input 'd' on the rising edge of this clock.\\nd: Data input signal that is captured by the flip-flop on the rising edge of the clock.\\n\\n[Output Signal Description]:\\nq: The output signal that holds the value of the input 'd' after the rising edge of the clock. It retains this value until the next rising edge of the clock.\\n\\n[Design Detail]: \\nmodule topmodule (\\n    input clk,    // Clocks are used in sequential circuits\\n    input d,\\n    output reg q );//\\n\\n    always @(posedge clk) begin\\n        q <= d;\\n    end\\n\\nendmodule\\n\\n\\n\\n\")]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Directory Loader\n",
    "from langchain_community.document_loaders import DirectoryLoader\n",
    "\n",
    "## load all the text files from the directory\n",
    "dir_loader=DirectoryLoader(\n",
    "    \"./knowledge_base\",\n",
    "    glob=\"**/*.txt\", ## Pattern to match files  \n",
    "    loader_cls= TextLoader, ##loader class to use\n",
    "    loader_kwargs={'encoding': 'utf-8'},\n",
    "    show_progress=False\n",
    "\n",
    ")\n",
    "\n",
    "documents=dir_loader.load()\n",
    "documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "db151a64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split 1 documents into 3 chunks\n",
      "\n",
      "Example chunk:\n",
      "Content : [Keyword]: Dff\n",
      "\n",
      "[Design Category]: Sequential Logic\n",
      "\n",
      "[Design Function Description]:\n",
      "This design is a simple D flip-flop. It captures the value of the input signal 'd' on the rising edge of the clock s...\n",
      "Metadata : {'source': './knowledge_base/dff.txt'}\n",
      "Total chunks created: 3\n"
     ]
    }
   ],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_core.documents import Document\n",
    "\n",
    "def split_documents(documents, chunk_size=500, chunk_overlap=50):\n",
    "    if not documents:\n",
    "        print(\"No documents to split.\")\n",
    "        return []\n",
    "\n",
    "    # If all items are plain strings, convert them to Document objects\n",
    "    if all(isinstance(d, str) for d in documents):\n",
    "        documents = [Document(page_content=doc, metadata={}) for doc in documents]\n",
    "\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=chunk_size,\n",
    "        chunk_overlap=chunk_overlap,\n",
    "        length_function=len,\n",
    "        separators=[\"\\n\\n\", \"\\n\", \" \"],\n",
    "    )\n",
    "\n",
    "    split_docs = text_splitter.split_documents(documents)\n",
    "    print(f\"Split {len(documents)} documents into {len(split_docs)} chunks\")\n",
    "\n",
    "    if split_docs:\n",
    "        print(\"\\nExample chunk:\")\n",
    "        print(f\"Content : {split_docs[0].page_content[:200]}...\")\n",
    "        print(f\"Metadata : {split_docs[0].metadata}\")\n",
    "\n",
    "    return split_docs\n",
    "\n",
    "# --- New part for handling a .txt file ---\n",
    "\n",
    "# 1. Load the text file using LangChain's TextLoader\n",
    "# Make sure to replace 'your_file.txt' with the correct file path.\n",
    "try:\n",
    "    loader = TextLoader(\"./knowledge_base/dff.txt\")\n",
    "    documents = loader.load()\n",
    "    \n",
    "    # 2. Split the loaded documents\n",
    "    chunks = split_documents(documents, chunk_size=500, chunk_overlap=50)\n",
    "    print(f\"Total chunks created: {len(chunks)}\")\n",
    "    \n",
    "except FileNotFoundError:\n",
    "    print(\"The file 'your_file.txt' was not found. Please check the file path.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fc783383",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\shrut\\OneDrive\\Desktop\\RAG_RTL\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "###Embedding and VectorStoreDB\n",
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import chromadb\n",
    "from chromadb.config import Settings\n",
    "import uuid\n",
    "from typing import List,Dict,Any,Tuple\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7c48290a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading embedding model:all-MiniLM-L6-v2\n",
      "Model loaded successfully. Embedding dimension: 384\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<__main__.EmbeddingManager at 0x1f2b8849ad0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class EmbeddingManager:\n",
    "    \"\"\"Handles document embedding generation using SentenceTransformer\"\"\"\n",
    "    def __init__(self,model_name:str=\"all-MiniLM-L6-v2\"):\n",
    "        \"\"\"\n",
    "        Intialize the embedding manager\n",
    "        Args:\n",
    "           model_name:HuggingFace model name for sentence embedding\n",
    "        \"\"\"\n",
    "        self.model_name = model_name\n",
    "        self.model = None\n",
    "        self._load_model()\n",
    "    \n",
    "    def _load_model(self):\n",
    "        \"\"\"Load the SentenceTransformer model\"\"\"\n",
    "        try:\n",
    "            print(f\"Loading embedding model:{self.model_name}\")\n",
    "            self.model =SentenceTransformer(self.model_name)\n",
    "            print(f\"Model loaded successfully. Embedding dimension: {self.model.get_sentence_embedding_dimension()}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading model {self.model_name}:{e}\")\n",
    "            raise\n",
    "    \n",
    "    def generate_embeddingd(self,texts:List[str])->np.ndarray:\n",
    "        \"\"\"AnyGenerate embeddings for a list of texts\n",
    "        Args:\n",
    "        texts:list of text strings to embed\n",
    "        Returns:\n",
    "        numpy array of embeddings with shape (len(texts),embedding_dim)\n",
    "        \"\"\"\n",
    "        if not self.model:\n",
    "            raise ValueError(\"Model not loaded\")\n",
    "        print(f\"Generating embeddings for {len(texts)} texts...\")\n",
    "        embeddings = self.model.encode(texts,show_progress_bar=True)\n",
    "        print(f\"Generated embeddings with shape: {embeddings.shape}\")\n",
    "        return embeddings\n",
    "embedding_manager= EmbeddingManager()\n",
    "embedding_manager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "773de0a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector store initialized. Collection: txt_documents\n",
      "Existing documents in collection: 0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<__main__.VectorStore at 0x1f2b8313c10>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#VectorStore:\n",
    "import os\n",
    "class VectorStore:\n",
    "     \"\"\" Manages document embedding in a ChromaDB vector store\"\"\"\n",
    "     def __init__(self, collection_name:str =\"txt_documents\",persist_directory:str=\"../data/vector_store\"):\n",
    "            \"\"\"\n",
    "            Initialize the vector store\n",
    "            Args:\n",
    "            collection_name:name of the ChromaDB collection\n",
    "            perist_directory: directory to persist the vector store\n",
    "            \"\"\"\n",
    "            self.collection_name = collection_name\n",
    "            self.persist_directory = persist_directory\n",
    "            self.client = None\n",
    "            self.collection = None\n",
    "            self._initialize_store()\n",
    "\n",
    "     def _initialize_store(self):\n",
    "        \"\"\"Initialize ChromaDB client and collection\"\"\"\n",
    "        try:\n",
    "            os.makedirs(self.persist_directory, exist_ok=True)\n",
    "            self.client =chromadb.PersistentClient(path=self.persist_directory)\n",
    "                \n",
    "            self.collection =self.client.get_or_create_collection(\n",
    "                    name=self.collection_name,\n",
    "                    metadata={\"description\":\"PDF document embeddings for RAG\"}\n",
    "            )\n",
    "            print(f\"Vector store initialized. Collection: {self.collection_name}\")\n",
    "            print(f\"Existing documents in collection: {self.collection.count()}\")\n",
    "\n",
    "        except Exception as e:\n",
    "                print(f\"Error initializing vector store:{e}\")\n",
    "                raise\n",
    "\n",
    "     def add_documents(self, documents: List[Any], embeddings: np.ndarray):\n",
    "            \"\"\"\n",
    "            Add documents and their embeddings to the vector store\n",
    "            Args:\n",
    "            documents: list of LangChain documents\n",
    "            embeddings: corresponding embedding for the documents\n",
    "            \"\"\"\n",
    "            if len(documents)!= len(embeddings):\n",
    "                raise ValueError(\"Number of documents must match number of embeddings\")\n",
    "\n",
    "            print(f\"Adding {len(documents)} documents to vector store ...\")\n",
    "\n",
    "            ids = []\n",
    "            metadatas = []\n",
    "            documents_text = []\n",
    "            embeddings_list =[]\n",
    "            for i, (doc,embedding) in enumerate(zip(documents, embeddings)):\n",
    "                #Generate unique ID\n",
    "                doc_id = f\"doc_{uuid.uuid4().hex[:8]}_{i}\"\n",
    "                ids.append(doc_id)\n",
    "                \n",
    "                #Prepare metadat\n",
    "                metadata = dict(doc.metadata)\n",
    "                metadata['doc index'] = i\n",
    "                metadata['content_length'] = len(doc.page_content)\n",
    "                metadatas.append(metadata)\n",
    "\n",
    "                #Document context\n",
    "                documents_text.append(doc.page_content)\n",
    "\n",
    "                #Embedding\n",
    "                embeddings_list.append(embedding.tolist())\n",
    "            \n",
    "            try: \n",
    "                self.collection.add(\n",
    "                    ids = ids,\n",
    "                    embeddings = embeddings_list,\n",
    "                    metadatas = metadatas,\n",
    "                    documents = documents_text\n",
    "                )\n",
    "                print(f\"Successfully added {len(documents)} documents to vector store\")\n",
    "                print(f\"Total documents in collection: {self.collection.count()}\")\n",
    "            except Exception as e:\n",
    "                print(f\"Error adding documents to vector store: {e}\")\n",
    "                raise\n",
    "\n",
    "vectorstore=VectorStore()\n",
    "vectorstore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "aafc98ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"[Keyword]: Dff\\n\\n[Design Category]: Sequential Logic\\n\\n[Design Function Description]:\\nThis design is a simple D flip-flop. It captures the value of the input signal 'd' on the rising edge of the clock signal 'clk' and outputs it as 'q'. The output 'q' retains its value until the next rising edge of 'clk'.\",\n",
       " \"[Input Signal Description]:\\nclk: Clock signal used to synchronize the data capture. The flip-flop captures the input 'd' on the rising edge of this clock.\\nd: Data input signal that is captured by the flip-flop on the rising edge of the clock.\\n\\n[Output Signal Description]:\\nq: The output signal that holds the value of the input 'd' after the rising edge of the clock. It retains this value until the next rising edge of the clock.\",\n",
       " '[Design Detail]: \\nmodule topmodule (\\n    input clk,    // Clocks are used in sequential circuits\\n    input d,\\n    output reg q );//\\n\\n    always @(posedge clk) begin\\n        q <= d;\\n    end\\n\\nendmodule']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts=[doc.page_content for doc in chunks]\n",
    "texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ab34097e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating embeddings for 3 texts...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  3.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated embeddings with shape: (3, 384)\n",
      "Adding 3 documents to vector store ...\n",
      "Successfully added 3 documents to vector store\n",
      "Total documents in collection: 3\n"
     ]
    }
   ],
   "source": [
    "embeddings =embedding_manager.generate_embeddingd(texts)\n",
    "vectorstore.add_documents(chunks,embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2063ca79",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RAGRetriever:\n",
    "    \"\"\"handles query-based retrieval from the vector store\"\"\"\n",
    "    def __init__(self, vector_store: VectorStore,embedding_manager: EmbeddingManager):\n",
    "        \"\"\"\n",
    "        Initialize the retriever\n",
    "        Args:\n",
    "           vector_store: Vector store containing document embeddings\n",
    "           embedding_manager: manager for generating query embeddings\n",
    "        \"\"\"\n",
    "        self.vector_store = vector_store\n",
    "        self.embedding_manager = embedding_manager\n",
    "\n",
    "    def retrieve(self, query:str, top_k: int =5, score_threshold: float=0.0)-> List[Dict[str,Any]]:\n",
    "        \"\"\"\n",
    "        Retrive relevant documents for a query\n",
    "        Args:\n",
    "        query: the search query\n",
    "        top_k: Number of top results to return\n",
    "        score_threshold: Minimum similarity score threshold\n",
    "\n",
    "        Returns:\n",
    "        List of dictionaries cantaining retrieved documents and metadata\n",
    "        \"\"\"\n",
    "        print(f\"Retrieving documents for query: '{query}\")\n",
    "        print(f\"Top K:{top_k}, score threshold: {score_threshold}\")\n",
    "\n",
    "        #Generate query embedding\n",
    "        query_embedding = self.embedding_manager.generate_embeddingd([query])[0]\n",
    "        \n",
    "         #Search in vector store\n",
    "        try:\n",
    "            results = self.vector_store.collection.query(\n",
    "                query_embeddings=[query_embedding.tolist()],\n",
    "                n_results=top_k\n",
    "            )\n",
    "            #Process results\n",
    "            retrieved_docs=[]\n",
    "            if results['documents'] and results['documents'][0]:\n",
    "                documents = results['documents'][0]\n",
    "                metadatas = results['metadatas'][0]\n",
    "                distances = results['distances'][0]\n",
    "                ids =results['ids'][0]\n",
    "\n",
    "                for i, (doc_id, document, metadata, distance) in enumerate(zip(ids,documents,metadatas,distances)):\n",
    "\n",
    "                    similarity_score = 1-distance\n",
    "                    if similarity_score>=score_threshold:\n",
    "                        retrieved_docs.append({\n",
    "                            'id':doc_id,\n",
    "                            'content':document,\n",
    "                            'metadata':metadata,\n",
    "                            'similarity_score':similarity_score,\n",
    "                            'distance':distance,\n",
    "                            'rank':i+1\n",
    "                        })\n",
    "                print(f\"Retrieved {len(retrieved_docs)} documents (after filtering)\")\n",
    "            else:\n",
    "                print(\"No documents found\")\n",
    "            return retrieved_docs\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"Error during retrieval: {e}\")\n",
    "            return[]\n",
    "        \n",
    "rag_retriever=RAGRetriever(vectorstore,embedding_manager)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c5937c7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieving documents for query: 'Inputs of a D flip flop?\n",
      "Top K:5, score threshold: 0.0\n",
      "Generating embeddings for 1 texts...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 17.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated embeddings with shape: (1, 384)\n",
      "Retrieved 2 documents (after filtering)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'id': 'doc_299b76d0_0',\n",
       "  'content': \"[Keyword]: Dff\\n\\n[Design Category]: Sequential Logic\\n\\n[Design Function Description]:\\nThis design is a simple D flip-flop. It captures the value of the input signal 'd' on the rising edge of the clock signal 'clk' and outputs it as 'q'. The output 'q' retains its value until the next rising edge of 'clk'.\",\n",
       "  'metadata': {'doc index': 0,\n",
       "   'content_length': 304,\n",
       "   'source': './knowledge_base/dff.txt'},\n",
       "  'similarity_score': 0.12181931734085083,\n",
       "  'distance': 0.8781806826591492,\n",
       "  'rank': 1},\n",
       " {'id': 'doc_bc9512d4_1',\n",
       "  'content': \"[Input Signal Description]:\\nclk: Clock signal used to synchronize the data capture. The flip-flop captures the input 'd' on the rising edge of this clock.\\nd: Data input signal that is captured by the flip-flop on the rising edge of the clock.\\n\\n[Output Signal Description]:\\nq: The output signal that holds the value of the input 'd' after the rising edge of the clock. It retains this value until the next rising edge of the clock.\",\n",
       "  'metadata': {'source': './knowledge_base/dff.txt',\n",
       "   'doc index': 1,\n",
       "   'content_length': 430},\n",
       "  'similarity_score': 0.09157943725585938,\n",
       "  'distance': 0.9084205627441406,\n",
       "  'rank': 2}]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rag_retriever\n",
    "rag_retriever.retrieve(\"Inputs of a D flip flop?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "eccf3600",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shrut\\AppData\\Local\\Temp\\ipykernel_30792\\3135994308.py:8: LangChainDeprecationWarning: The class `ChatOllama` was deprecated in LangChain 0.3.1 and will be removed in 1.0.0. An updated version of the class exists in the :class:`~langchain-ollama package and should be used instead. To use it run `pip install -U :class:`~langchain-ollama` and import as `from :class:`~langchain_ollama import ChatOllama``.\n",
      "  llm = ChatOllama(model=\"codellama\", temperature=0.1)\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.chat_models import ChatOllama\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# Replace the Groq model with your local Ollama-based Code Llama model\n",
    "llm = ChatOllama(model=\"codellama\", temperature=0.1)\n",
    "\n",
    "# The rag_simple function remains the same as it's model-agnostic\n",
    "def rag_simple(query, retriever, llm, top_k=3):\n",
    "    results = retriever.retrieve(query, top_k=top_k)\n",
    "    context = \"\\n\\n\".join([doc['content'] for doc in results]) if results else \"\"\n",
    "\n",
    "    if not context:\n",
    "        return \"No relevant documents found to answer the query.\"\n",
    "    \n",
    "    prompt = f\"\"\"Use the following context to answer the question concisely.\n",
    "    Context:\n",
    "    {context}\n",
    "    Question: {query}\n",
    "    Answer:\"\"\"\n",
    "    \n",
    "    response = llm.invoke(prompt)  # No need for a list in Ollama\n",
    "    return response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5c55601e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieving documents for query: 'Verilog Code for a D flip-flop\n",
      "Top K:3, score threshold: 0.0\n",
      "Generating embeddings for 1 texts...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 26.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated embeddings with shape: (1, 384)\n",
      "Retrieved 1 documents (after filtering)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```\n",
      "module d_ff(\n",
      "  input clk,\n",
      "  input d,\n",
      "  output reg q\n",
      ");\n",
      "always @(posedge clk) begin\n",
      "  if (d) begin\n",
      "    q <= 1'b1;\n",
      "  end else begin\n",
      "    q <= 1'b0;\n",
      "  end\n",
      "end\n",
      "endmodule\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "answer=rag_simple(\"Verilog Code for a D flip-flop\",rag_retriever,llm)\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "19db0201",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rag_advanced(query, retriever, llm, top_k=200, min_score=0, return_context=False):\n",
    "    \"\"\"\n",
    "    RAG pipeline with extra features:\n",
    "    - Returns answer, sources, confidence score, and optionally full context.\n",
    "    \"\"\"\n",
    "    results = retriever.retrieve(query, top_k=top_k, score_threshold=min_score)\n",
    "    if not results:\n",
    "        return {'answer': 'No relevant context found.', 'sources': [], 'confidence': 0.0, 'context': ''}\n",
    "    \n",
    "    # Prepare context and sources\n",
    "    context = \"\\n\\n\".join([doc['content'] for doc in results])\n",
    "    sources = [{\n",
    "        'source': doc['metadata'].get('source_file', doc['metadata'].get('source', 'unknown')),\n",
    "        'page': doc['metadata'].get('page', 'unknown'),\n",
    "        'score': doc['similarity_score'],\n",
    "        'preview': doc['content'][:300] + '...'\n",
    "    } for doc in results]\n",
    "    confidence = max([doc['similarity_score'] for doc in results])\n",
    "    \n",
    "    # Generate answer\n",
    "    prompt = f\"\"\"Use the following context to answer the question concisely.\\nContext:\\n{context}\\n\\nQuestion: {query}\\n\\nAnswer:\"\"\"\n",
    "    response = llm.invoke([prompt.format(context=context, query=query)])\n",
    "    \n",
    "    output = {\n",
    "        'answer': response.content,\n",
    "        'sources': sources,\n",
    "        'confidence': confidence\n",
    "    }\n",
    "    if return_context:\n",
    "        output['context'] = context\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1a5462ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieving documents for query: 'I would like you to implement a module named TopModule with the following interface. All input and output ports are one bit unless otherwise specified.- input clk, - input d, - output q. The module should implement a single D flip-flop. Assume all sequential logic is trigerred on the positive edge of the clock.\n",
      "Top K:200, score threshold: 0\n",
      "Generating embeddings for 1 texts...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 18.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated embeddings with shape: (1, 384)\n",
      "Retrieved 2 documents (after filtering)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer: \n",
      "Here's an example implementation of the TopModule module with the specified interface:\n",
      "```scss\n",
      "module topmodule (\n",
      "    input clk,\n",
      "    input d,\n",
      "    output reg q );\n",
      "\n",
      "    always @(posedge clk) begin\n",
      "        q <= d;\n",
      "    end\n",
      "\n",
      "endmodule\n",
      "```\n",
      "This implementation uses a single D flip-flop to capture the value of the input signal 'd' on the rising edge of the clock signal 'clk' and outputs it as 'q'. The output 'q' retains its value until the next rising edge of 'clk'.\n"
     ]
    }
   ],
   "source": [
    "result = rag_advanced(\"I would like you to implement a module named TopModule with the following interface. All input and output ports are one bit unless otherwise specified.- input clk, - input d, - output q. The module should implement a single D flip-flop. Assume all sequential logic is trigerred on the positive edge of the clock.\", rag_retriever, llm,top_k=200,min_score=0,return_context=True)\n",
    "print(\"Answer:\", result['answer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05987988",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "RAG_RTL",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
